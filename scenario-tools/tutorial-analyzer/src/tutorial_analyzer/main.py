"""Main orchestration across all stages.

Pipeline:
  Analyze ‚Üí Simulate Learner ‚Üí Diagnose Issues ‚Üí
  ‚Üí Generate Improvements ‚Üí [HUMAN APPROVAL] ‚Üí
  ‚Üí Evaluate Improvements ‚Üí Synthesize Recommendations ‚Üí
  ‚Üí [QUALITY CHECK] ‚Üí Loop or Finalize
"""

import asyncio
import sys
from pathlib import Path

from .analyzer.core import analyze
from .critic.core import evaluate_improvements
from .diagnostician.core import diagnose_issues
from .improver.core import generate_improvements
from .learner_simulator.core import simulate_learner
from .state import load_state
from .state import save_state
from .synthesizer.core import synthesize_recommendations


def _generate_report(state: dict, tutorial_path: Path, report_path: Path) -> None:
    """Generate comprehensive markdown analysis report."""
    with open(report_path, "w") as f:
        f.write("# Tutorial Analysis Report\n\n")
        f.write(f"**Tutorial:** `{tutorial_path.name}`\n")
        f.write(f"**Quality Score:** {state.get('synthesis', {}).get('quality_score', 'N/A')}\n\n")
        f.write("---\n\n")

        # Diagnosis Summary
        if "diagnosis" in state:
            f.write("## Diagnosis Summary\n\n")
            diagnosis = state["diagnosis"]
            if "summary" in diagnosis:
                summary = diagnosis["summary"]
                f.write(f"**Primary Issue:** {summary.get('primary_pedagogical_failure', 'N/A')}\n\n")
                f.write(
                    f"**Issues Found:** {summary.get('critical_issues', 0)} critical, "
                    f"{summary.get('major_issues', 0)} major, {summary.get('minor_issues', 0)} minor\n\n"
                )

            # Detailed issues
            if "issues" in diagnosis and isinstance(diagnosis["issues"], list):
                f.write("### Identified Issues\n\n")
                for issue in diagnosis["issues"]:
                    if isinstance(issue, dict):
                        severity = issue.get("severity", "unknown").upper()
                        f.write(f"- **[{severity}]** {issue.get('issue', 'Unknown issue')}\n")
                f.write("\n")

        # Learner Experience
        if "learner_experience" in state:
            f.write("## From Learner Perspective\n\n")
            exp = state["learner_experience"]
            if isinstance(exp, dict):
                if "issue" in exp:
                    f.write(f"**Confusion Point:** {exp['issue']}\n\n")
                if "location" in exp:
                    f.write(f"**Location:** {exp['location']}\n\n")
            f.write("\n")

        # Improvements
        if "improvements" in state:
            f.write("## Recommended Improvements\n\n")
            improvements_data = state["improvements"]

            # Handle single improvement object
            if "title" in improvements_data and "description" in improvements_data:
                suggestions = [improvements_data]
            else:
                suggestions = improvements_data.get("suggestions") or improvements_data.get("improvements", [])

            if isinstance(suggestions, list):
                for i, suggestion in enumerate(suggestions, 1):
                    if isinstance(suggestion, dict):
                        f.write(f"### {i}. {suggestion.get('title', 'Untitled')}\n\n")
                        f.write(f"{suggestion.get('description', 'No description')}\n\n")
                        if "location" in suggestion:
                            f.write(f"**Location:** {suggestion.get('location')}\n\n")
                    else:
                        f.write(f"### {i}. {suggestion}\n\n")

        # Implementation Priority
        if "synthesis" in state:
            f.write("## Implementation Priority\n\n")
            synthesis = state["synthesis"]
            recommendations = synthesis.get("recommendations", [])
            if isinstance(recommendations, list):
                for i, rec in enumerate(recommendations, 1):
                    f.write(f"{i}. {rec}\n")
            f.write("\n")

        f.write("---\n\n")
        f.write("*Generated by tutorial-analyzer using Multi-Config Metacognitive Recipe Pattern*\n")


async def evolve_tutorial(tutorial_path: Path, focus_areas: list[str] | None = None):
    """Multi-stage metacognitive recipe for tutorial evolution.

    Args:
        tutorial_path: Path to tutorial markdown file
        focus_areas: Optional list of areas to focus on (e.g., ["clarity", "examples"])

    Returns:
        Dict with final synthesis results
    """

    state = load_state()
    content = tutorial_path.read_text()

    # Stage 1: Content analysis (autonomous)
    if "analysis" not in state:
        print("Stage 1/7: Analyzing tutorial structure...")
        state["analysis"] = await analyze(content)
        save_state(state)
        print("‚úì Analysis complete")

    # Stage 2: Learner simulation (autonomous)
    if "learner_experience" not in state:
        print("Stage 2/7: Simulating learner experience...")
        state["learner_experience"] = await simulate_learner(content, state["analysis"])
        save_state(state)
        print("‚úì Simulation complete")

    # Stage 3: Issue diagnosis (autonomous)
    if "diagnosis" not in state:
        print("Stage 3/7: Diagnosing pedagogical issues...")
        state["diagnosis"] = await diagnose_issues(state["learner_experience"], state["analysis"])
        save_state(state)
        print("‚úì Diagnosis complete")

    # Stage 4: Improvement generation (autonomous)
    if "improvements" not in state:
        print("Stage 4/7: Generating improvement suggestions...")
        state["improvements"] = await generate_improvements(state["diagnosis"], focus_areas)
        save_state(state)
        print("‚úì Improvements generated")

    # Stage 5: HUMAN-IN-LOOP (strategic decision point)
    if "human_approval" not in state:
        print("\n" + "=" * 60)
        print("PROPOSED IMPROVEMENTS:")
        print("=" * 60)

        # Display improvements (defensive: handle multiple formats)
        improvements_data = state["improvements"]

        # Handle if LLM returned single improvement instead of array
        if "title" in improvements_data and "description" in improvements_data:
            # Single improvement object - wrap in array
            suggestions = [improvements_data]
        else:
            # Look for suggestions array
            suggestions = improvements_data.get("suggestions") or improvements_data.get("improvements", [])

        if isinstance(suggestions, list) and len(suggestions) > 0:
            for i, improvement in enumerate(suggestions, 1):
                if isinstance(improvement, dict):
                    print(f"\n{i}. {improvement.get('title', 'Untitled')}")
                    print(f"   {improvement.get('description', 'No description')}")
                else:
                    print(f"\n{i}. {improvement}")
        else:
            print("\n[No improvements found in response]")
            print(f"Received: {list(improvements_data.keys())}")

        print("=" * 60)

        approval = input("\nApprove these improvements? (yes/no/modify): ").lower()

        if approval == "modify":
            modifications = input("What modifications? ")
            state["improvements"]["modifications"] = modifications

        state["human_approval"] = approval
        save_state(state)

        if approval == "no":
            return {"status": "rejected", "reason": "User rejected improvements"}

    # Stage 6: Evaluate improvements (autonomous)
    if "critique" not in state:
        print("\nStage 5/7: Evaluating improvement quality...")
        state["critique"] = await evaluate_improvements(state["improvements"], state["diagnosis"])
        save_state(state)
        print("‚úì Evaluation complete")

    # Stage 7: Synthesize final recommendations (autonomous)
    if "synthesis" not in state:
        print("Stage 6/7: Synthesizing final recommendations...")
        state["synthesis"] = await synthesize_recommendations(
            state["critique"], state["improvements"], state["diagnosis"]
        )
        save_state(state)
        print("‚úì Synthesis complete")

    # CODE makes decision: Check quality, iterate if needed
    quality_score = float(state["synthesis"].get("quality_score", 0))
    iterations = state.get("iterations", 0)

    print(f"\nQuality Score: {quality_score}")

    if quality_score < 0.8 and iterations < 3:
        print(f"Score below threshold. Iterating... (attempt {iterations + 1}/3)")
        state["iterations"] = iterations + 1
        # Clear stages that need regeneration
        del state["improvements"]  # Regenerate with feedback
        del state["human_approval"]  # Ask again
        del state["critique"]  # Re-evaluate new improvements
        del state["synthesis"]  # Re-synthesize with new evaluation
        save_state(state)
        return await evolve_tutorial(tutorial_path, focus_areas)

    # Stage 8: Generate markdown report (in current directory, not tutorial directory)
    print("\nStage 7/7: Generating analysis report...")
    report_path = Path.cwd() / f"{tutorial_path.stem}_analysis.md"
    _generate_report(state, tutorial_path, report_path)
    print(f"‚úì Report saved to: {report_path}")

    print("\n‚úì Tutorial analysis complete!")
    return {"report_path": str(report_path), "quality_score": quality_score}


def cli():
    """CLI entry point.

    Usage:
        tutorial-analyzer <tutorial.md> [focus_area1] [focus_area2] ...

    Example:
        tutorial-analyzer tutorial.md clarity examples
    """
    if len(sys.argv) < 2:
        print("Usage: tutorial-analyzer <tutorial.md> [focus_area1] [focus_area2] ...")
        print("\nExamples:")
        print("  tutorial-analyzer tutorial.md")
        print("  tutorial-analyzer tutorial.md clarity examples code-quality")
        sys.exit(1)

    tutorial_path = Path(sys.argv[1])
    focus_areas = sys.argv[2:] if len(sys.argv) > 2 else None

    # Validate input
    if not tutorial_path.exists():
        print(f"Error: {tutorial_path} does not exist")
        sys.exit(1)

    if not tutorial_path.is_file():
        print(f"Error: {tutorial_path} is not a file")
        sys.exit(1)

    # Run
    result = asyncio.run(evolve_tutorial(tutorial_path, focus_areas))

    # Report
    if result.get("status") == "rejected":
        print(f"\n‚ùå Process stopped: {result.get('reason')}")
        sys.exit(1)
    else:
        print(f"\n‚úÖ Final quality score: {result.get('quality_score', 'N/A')}")
        print(f"üìÑ Analysis report: {result.get('report_path', 'N/A')}")


if __name__ == "__main__":
    cli()
